{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The EDSII Construction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides code used for the construction of the European Digital Social Innovation Index. The data can be downloaded from: https://www.nesta.org.uk/documents/1395/Downloadable_data_EDSII.xlsx. \n",
    "\n",
    "For more information about the EDSII see here: https://www.nesta.org.uk/feature/european-digital-social-innovation-index/\n",
    "\n",
    "Please note that due to random processes used in data imputation and different degrees of number rounding used, the output from this code may contain some slight differences to data presented online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "URL = 'https://media.nesta.org.uk/documents/Downloadable_data_EDSII.xlsx'\n",
    "r = requests.get(URL)\n",
    "\n",
    "with BytesIO(r.content) as f:\n",
    "    standardised_data = pd.read_excel(f, sheet_name = 'Data', encoding = \"ISO-8859-1\")[1:61]\n",
    "    colnames = pd.read_excel(f, sheet_name = 'Data').iloc[0]\n",
    "\n",
    "# Upload data\n",
    "#standardised_data = pd.read_excel(URL, sheet_name = 'Data', encoding = \"ISO-8859-1\")[1:61] \n",
    "\n",
    "## Fix column names\n",
    "\n",
    "#colnames = pd.read_excel(URL, sheet_name = 'Data').iloc[0]\n",
    "colnames[0:2] = ['City', 'Country']\n",
    "standardised_data.columns = colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function removes outliers by transforming high (low) outliers to have the same value as the highest (lowest) existing value in that variable which falls above Q3 + 1.5 IQR or below Q1 − 1.5 IQR. \n",
    "def windsor(df):\n",
    "    windsored_data = df.copy()\n",
    "    for column in windsored_data.iloc[:, 2:]:\n",
    "        Q1 = windsored_data[column].quantile(0.25)\n",
    "        Q3 = windsored_data[column].quantile(0.75)\n",
    "        Max = max(windsored_data[column].dropna())\n",
    "        Min = min(windsored_data[column].dropna())\n",
    "        IQR = Q3 - Q1\n",
    "        upperlimit = Q3 + 1.5 * IQR\n",
    "        lowerlimit = Q1 - 1.5 * IQR\n",
    "        Max_nonoutlier = max(windsored_data[windsored_data[column] < upperlimit][column].dropna())\n",
    "        Min_nonoutlier = min(windsored_data[windsored_data[column] > lowerlimit][column].dropna())\n",
    "        while Max > upperlimit:\n",
    "            windsored_data[column] = windsored_data[column].replace(Max,Max_nonoutlier)\n",
    "            Max = max(windsored_data[column].dropna())\n",
    "        while Min < lowerlimit:\n",
    "            windsored_data[column] = windsored_data[column].replace(Min,Min_nonoutlier)\n",
    "            Min = max(windsored_data[column].dropna())\n",
    "    return windsored_data\n",
    "             \n",
    "# This function normalises columns to be within an identical min-max range of [0.1, 0.9].\n",
    "def normalise(df):\n",
    "    normalized_data = df.copy()\n",
    "    for column in df.columns:\n",
    "        max_value = df[column].max()\n",
    "        min_value = df[column].min()\n",
    "        normalized_data[column] = (0.8 * (df[column] - min_value) / (max_value - min_value))+0.1\n",
    "    return normalized_data\n",
    "\n",
    "# This function aggregates indicators into themes and themes into a final index score\n",
    "def aggregate(df_in, varweights, bucketweights):\n",
    "    df_copy = df_in.copy()\n",
    "    colnames = df_copy.columns\n",
    "    # Apply variable weights & artihmetic mean\n",
    "    for i in range(0,len(colnames)):\n",
    "        df_copy[colnames[i]] = df_in[df_in.columns[i]]*varweights[i]\n",
    "    combs = [[0,1,2,3,4,5],[6,7,8,9,10,11],[12,13,14,15,16],[17,18,19,20,21,22],[23,24,25,26,27],[28,29,30,31]]\n",
    "    count=0\n",
    "    for l in combs:\n",
    "        cols = l\n",
    "        count +=1\n",
    "        newcol = \"B\" + str(count)\n",
    "        df_copy[newcol] = df_copy.iloc[:,cols].sum(axis=1)/sum(varweights[cols[0]:(cols[-1]+1)])\n",
    "    theme_scores = df_copy.iloc[:,-6:]\n",
    "    theme_scores.columns = ['Civil Society', 'Collaboration', 'Skills', 'Infrastructure', 'Funding', 'Diversity and Inclusion']\n",
    "    df_copy = normalise(df_copy)\n",
    "    # Apply bucket weights & geometric mean\n",
    "    for j in range(0,6):\n",
    "        oldcol = \"B\" + str(j + 1)\n",
    "        newcol = \"C\" + str(j + 1)\n",
    "        df_copy[newcol] = df_copy[oldcol] ** bucketweights[j]\n",
    "    collist = [x for x in range(38,len(df_copy.columns))]\n",
    "    list_out = list(df_copy.iloc[:,collist].prod(axis=1)**(1/sum(bucketweights)))\n",
    "    return [list_out,theme_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of outliers\n",
    "windsored_data = windsor(standardised_data) \n",
    "\n",
    "# Normalisaion of columns to identical min-max range of [0.1, 0.9]\n",
    "normalized_data = normalise(windsored_data.iloc[:, 2:])\n",
    "normalized_data = pd.DataFrame(normalized_data, dtype='float')\n",
    "\n",
    "# Imputation of missing values\n",
    "# Some indicators are made up of several measures. Where this is the case we merge measures into a single indicator by taking their arithmetic mean.\n",
    "normalized_data['Government collaboration with tech sector'] = normalized_data[['Government collaboration with tech sector 1','Government collaboration with tech sector 2','Government collaboration with tech sector 3']].mean(axis=1)\n",
    "normalized_data['Diversity within the tech sector'] = normalized_data[['Diversity within the tech sector 1','Diversity within the tech sector 2']].mean(axis=1)\n",
    "normalized_data['Diversity within civil society'] = normalized_data[['Diversity within civic society 1','Diversity within civic society 2']].mean(axis=1)\n",
    "normalized_data['Openness of data'] = normalized_data[['Openness of data 1','Openness of data 2']].mean(axis=1)\n",
    "normalized_data['Access to Business, HR, legal, marketing, design and media support'] = normalized_data[['Access to Business, HR, legal, marketing, design and media support 1','Access to Business, HR, legal, marketing, design and media support 2','Access to Business, HR, legal, marketing, design and media support 3','Access to Business, HR, legal, marketing, design and media support 4','Access to Business, HR, legal, marketing, design and media support 5']].mean(axis=1)\n",
    "normalized_data['Social cohesion'] = normalized_data[['Social cohesion 1','Social cohesion 2','Social cohesion 3','Social cohesion 4']].mean(axis=1)\n",
    "normalized_data['Access to fast broadband and mobile internet 1'] = normalized_data[['Access to fast broadband and mobile internet 1','Access to fast broadband and mobile internet 2','Access to fast broadband and mobile internet 3']].mean(axis=1)\n",
    "normalized_data['Access to fast broadband and mobile internet 2'] = normalized_data[['Access to fast broadband and mobile internet 4','Access to fast broadband and mobile internet 5','Access to fast broadband and mobile internet 6']].mean(axis=1)\n",
    "normalized_data['Access to fast broadband and mobile internet'] = normalized_data[['Access to fast broadband and mobile internet 1','Access to fast broadband and mobile internet 2']].mean(axis=1)\n",
    "normalized_data = normalized_data[['Access to Volunteers', 'Positve attitudes to civil society', 'Social cohesion','Individual giving', 'Public advocacy for DSI','Presence of supportive governent policy for social purpose inititives', 'Events where people can meet to network / discuss DSI', 'Online collaboration','Tech sector collaboration with civil society','Government collaboration with civic society', 'Government collaboration with tech sector','Engagement with DSI','Access to Business, HR, legal, marketing, design and media support','Access to employees with data skills','Access to employees with service design skills','Access to employees with Software Engineering / Development skills','Presence of research institutions with expertise in DSI (standardized by pop.)','Access to fast broadband and mobile internet','Access to flexible work space','Openness of data','Access to fabrication and manufactoring facilities','Presence of socially focussed business support','Ease of starting a business', 'Availability of Seed Grant Funding','Availability of Major Grant Funding', 'Flexibility of funding','Availability of impact investment','Willingness of public and social sector procure from SMEs','Diversity within the tech sector', 'Diversity within civil society','Inclusivity of innovation', 'Digital inclusion']]\n",
    "\n",
    "#Replace missing values replaced with estimated values\n",
    "XY_incomplete = normalized_data\n",
    "\n",
    "n_imputations = 5\n",
    "XY_completed = []\n",
    "for i in range(n_imputations):\n",
    "    imputer = IterativeImputer(n_iter=5, sample_posterior=True, random_state=i)\n",
    "    XY_completed.append(imputer.fit_transform(XY_incomplete))\n",
    "\n",
    "XY_completed_mean = np.mean(XY_completed, 0)\n",
    "XY_completed_std = np.std(XY_completed, 0)\n",
    "imputed_data = pd.DataFrame(XY_completed_mean)\n",
    "imputed_data.columns = normalized_data.columns\n",
    "imputed_data.index = normalized_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting and aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator weights\n",
    "varweights_stup = [18.18, 18.18, 18.18, 9.10, 18.18, 18.18, 5.26, 10.52, 21.05, 21.05, 21.05, 21.05, 20, 20, 20, 20, 20, 22.22, 16.67, 22.22, 11.11, 16.67, 11.11, 16.67, 8.33, 25, 25, 25, 22.22, 22.22, 22.22, 33.34]\n",
    "bucketweights_stup = [20, 17.5, 17.5, 15, 15, 15]\n",
    "df_normin = imputed_data\n",
    "\n",
    "# Calculation of index scores\n",
    "results_stup = aggregate(df_normin, varweights_stup, bucketweights_stup)\n",
    "index_score = pd.DataFrame(results_stup[0], columns=['Index Score'], index=df_normin.index)\n",
    "for column in index_score.columns:\n",
    "         index_score[column] = ((index_score[column] - 0.1) / (0.8))# rescaling to same scale as presented online       \n",
    "index_score = pd.concat([standardised_data.iloc[:, :1],index_score],axis=1)\n",
    "theme_scores = pd.DataFrame(results_stup[1], columns=['Civil Society', 'Collaboration', 'Skills', 'Infrastructure', 'Funding', 'Diversity and Inclusion'], index=df_normin.index)\n",
    "for column in theme_scores.columns:\n",
    "         theme_scores[column] = ((theme_scores[column] - 0.1) / (0.8))# rescaling to same scale as presented online     \n",
    "theme_scores = pd.concat([standardised_data.iloc[:, :1],theme_scores],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print final index score\n",
    "print(index_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print final theme scores\n",
    "print(theme_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
