{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The EDSII Construction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides code used for the construction of the European Digital Social Innovation Index. \n",
    "\n",
    "The data can be downloaded from: https://www.nesta.org.uk/documents/1395/Downloadable_data_EDSII.xlsx. \n",
    "\n",
    "For more information about the EDSII, including a detailed methodology, discussion of key results, examples of how governments are already supporting DSI and an interactive data visualisation, see: https://www.nesta.org.uk/feature/european-digital-social-innovation-index/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbone\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "XLRDError",
     "evalue": "Unsupported format, or corrupt file: Expected BOF record; found b'<?xml ve'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f9a4f3494f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mstandardised_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ISO-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m61\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mcolnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mformatting_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mon_demand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0mragged_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         )\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mbk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mbiff_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36mgetbof\u001b[1;34m(self, rqd_stream)\u001b[0m\n\u001b[0;32m   1269\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected BOF record; met end of file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1271\u001b[1;33m             \u001b[0mbof_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected BOF record; found %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1272\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36mbof_error\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reqd: 0x%04x\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrqd_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'<?xml ve'"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Import data\n",
    "URL = 'https://media.nesta.org.uk/documents/Downloadable_data_EDSII.xlsx'\n",
    "r = requests.get(URL)\n",
    "\n",
    "with BytesIO(r.content) as f:\n",
    "    standardised_data = pd.read_excel(f, sheet_name = 'Data', encoding = \"ISO-8859-1\")[1:61]\n",
    "    colnames = pd.read_excel(f, sheet_name = 'Data').iloc[0]\n",
    "\n",
    "colnames[0:2] = ['City', 'Country']\n",
    "standardised_data.columns = colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes outliers by transforming high (low) outliers to have the same value as the highest (lowest) existing value in that variable which falls above Q3 + 1.5 IQR or below Q1 − 1.5 IQR. \n",
    "def windsor(df):\n",
    "    windsored_data = df.copy()\n",
    "    for column in windsored_data.iloc[:, 2:]:\n",
    "        Q1 = windsored_data[column].quantile(0.25)\n",
    "        Q3 = windsored_data[column].quantile(0.75)\n",
    "        Max = max(windsored_data[column].dropna())\n",
    "        Min = min(windsored_data[column].dropna())\n",
    "        IQR = Q3 - Q1\n",
    "        upperlimit = Q3 + 1.5 * IQR\n",
    "        lowerlimit = Q1 - 1.5 * IQR\n",
    "        Max_nonoutlier = max(windsored_data[windsored_data[column] < upperlimit][column].dropna())\n",
    "        Min_nonoutlier = min(windsored_data[windsored_data[column] > lowerlimit][column].dropna())\n",
    "        while Max > upperlimit:\n",
    "            windsored_data[column] = windsored_data[column].replace(Max,Max_nonoutlier)\n",
    "            Max = max(windsored_data[column].dropna())\n",
    "        while Min < lowerlimit:\n",
    "            windsored_data[column] = windsored_data[column].replace(Min,Min_nonoutlier)\n",
    "            Min = max(windsored_data[column].dropna())\n",
    "    return windsored_data\n",
    "             \n",
    "# This function normalises columns to be within an identical min-max range of [0.1, 0.9].\n",
    "def normalise(df):\n",
    "    normalized_data = df.copy()\n",
    "    for column in df.columns:\n",
    "        max_value = df[column].max()\n",
    "        min_value = df[column].min()\n",
    "        normalized_data[column] = (0.8 * (df[column] - min_value) / (max_value - min_value))+0.1\n",
    "    return normalized_data\n",
    "\n",
    "# This function aggregates indicators into themes and themes into a final index score\n",
    "def aggregate(df_in, varweights, bucketweights):\n",
    "    df_copy = df_in.copy()\n",
    "    colnames = df_copy.columns\n",
    "    # Apply variable weights & artihmetic mean\n",
    "    for i in range(0,len(colnames)):\n",
    "        df_copy[colnames[i]] = df_in[df_in.columns[i]]*varweights[i]\n",
    "    combs = [[0,1,2,3,4,5],[6,7,8,9,10,11],[12,13,14,15,16],[17,18,19,20,21,22],[23,24,25,26,27],[28,29,30,31]]\n",
    "    count=0\n",
    "    for l in combs:\n",
    "        cols = l\n",
    "        count +=1\n",
    "        newcol = \"B\" + str(count)\n",
    "        df_copy[newcol] = df_copy.iloc[:,cols].sum(axis=1)/sum(varweights[cols[0]:(cols[-1]+1)])\n",
    "    theme_scores = df_copy.iloc[:,-6:]\n",
    "    theme_scores.columns = ['Civil Society', 'Collaboration', 'Skills', 'Infrastructure', 'Funding', 'Diversity and Inclusion']\n",
    "    df_copy = normalise(df_copy)\n",
    "    # Apply bucket weights & geometric mean\n",
    "    for j in range(0,6):\n",
    "        oldcol = \"B\" + str(j + 1)\n",
    "        newcol = \"C\" + str(j + 1)\n",
    "        df_copy[newcol] = df_copy[oldcol] ** bucketweights[j]\n",
    "    collist = [x for x in range(38,len(df_copy.columns))]\n",
    "    list_out = list(df_copy.iloc[:,collist].prod(axis=1)**(1/sum(bucketweights)))\n",
    "    return [list_out,theme_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of outliers\n",
    "windsored_data = windsor(standardised_data) \n",
    "\n",
    "# Normalisaion of columns to identical min-max range of [0.1, 0.9]\n",
    "normalized_data = normalise(windsored_data.iloc[:, 2:])\n",
    "normalized_data = pd.DataFrame(normalized_data, dtype='float')\n",
    "\n",
    "# Imputation of missing values\n",
    "# Some indicators are made up of several measures. Where this is the case we merge measures into a single indicator by taking their arithmetic mean.\n",
    "normalized_data['Government collaboration with tech sector'] = normalized_data[['Government collaboration with tech sector 1','Government collaboration with tech sector 2','Government collaboration with tech sector 3']].mean(axis=1)\n",
    "normalized_data['Diversity within the tech sector'] = normalized_data[['Diversity within the tech sector 1','Diversity within the tech sector 2']].mean(axis=1)\n",
    "normalized_data['Diversity within civil society'] = normalized_data[['Diversity within civic society 1','Diversity within civic society 2']].mean(axis=1)\n",
    "normalized_data['Openness of data'] = normalized_data[['Openness of data 1','Openness of data 2']].mean(axis=1)\n",
    "normalized_data['Access to Business, HR, legal, marketing, design and media support'] = normalized_data[['Access to Business, HR, legal, marketing, design and media support 1','Access to Business, HR, legal, marketing, design and media support 2','Access to Business, HR, legal, marketing, design and media support 3','Access to Business, HR, legal, marketing, design and media support 4','Access to Business, HR, legal, marketing, design and media support 5']].mean(axis=1)\n",
    "normalized_data['Social cohesion'] = normalized_data[['Social cohesion 1','Social cohesion 2','Social cohesion 3','Social cohesion 4']].mean(axis=1)\n",
    "normalized_data['Access to fast broadband and mobile internet 1'] = normalized_data[['Access to fast broadband and mobile internet 1','Access to fast broadband and mobile internet 2','Access to fast broadband and mobile internet 3']].mean(axis=1)\n",
    "normalized_data['Access to fast broadband and mobile internet 2'] = normalized_data[['Access to fast broadband and mobile internet 4','Access to fast broadband and mobile internet 5','Access to fast broadband and mobile internet 6']].mean(axis=1)\n",
    "normalized_data['Access to fast broadband and mobile internet'] = normalized_data[['Access to fast broadband and mobile internet 1','Access to fast broadband and mobile internet 2']].mean(axis=1)\n",
    "normalized_data = normalized_data[['Access to Volunteers', 'Positve attitudes to civil society', 'Social cohesion','Individual giving', 'Public advocacy for DSI','Presence of supportive governent policy for social purpose inititives', 'Events where people can meet to network / discuss DSI', 'Online collaboration','Tech sector collaboration with civil society','Government collaboration with civic society', 'Government collaboration with tech sector','Engagement with DSI','Access to Business, HR, legal, marketing, design and media support','Access to employees with data skills','Access to employees with service design skills','Access to employees with Software Engineering / Development skills','Presence of research institutions with expertise in DSI (standardized by pop.)','Access to fast broadband and mobile internet','Access to flexible work space','Openness of data','Access to fabrication and manufactoring facilities','Presence of socially focussed business support','Ease of starting a business', 'Availability of Seed Grant Funding','Availability of Major Grant Funding', 'Flexibility of funding','Availability of impact investment','Willingness of public and social sector procure from SMEs','Diversity within the tech sector', 'Diversity within civil society','Inclusivity of innovation', 'Digital inclusion']]\n",
    "\n",
    "#Replace missing values replaced with estimated values\n",
    "XY_incomplete = normalized_data\n",
    "\n",
    "n_imputations = 5\n",
    "XY_completed = []\n",
    "for i in range(n_imputations):\n",
    "    imputer = IterativeImputer(n_iter=5, sample_posterior=True, random_state=i)\n",
    "    XY_completed.append(imputer.fit_transform(XY_incomplete))\n",
    "\n",
    "XY_completed_mean = np.mean(XY_completed, 0)\n",
    "XY_completed_std = np.std(XY_completed, 0)\n",
    "imputed_data = pd.DataFrame(XY_completed_mean)\n",
    "imputed_data.columns = normalized_data.columns\n",
    "imputed_data.index = normalized_data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting and aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator weights\n",
    "varweights_stup = [18.18, 18.18, 18.18, 9.10, 18.18, 18.18, 5.26, 10.52, 21.05, 21.05, 21.05, 21.05, 20, 20, 20, 20, 20, 22.22, 16.67, 22.22, 11.11, 16.67, 11.11, 16.67, 8.33, 25, 25, 25, 22.22, 22.22, 22.22, 33.34]\n",
    "bucketweights_stup = [20, 17.5, 17.5, 15, 15, 15]\n",
    "df_normin = imputed_data\n",
    "\n",
    "# Calculation of index scores\n",
    "results_stup = aggregate(df_normin, varweights_stup, bucketweights_stup)\n",
    "index_score = pd.DataFrame(results_stup[0], columns=['Index Score'], index=df_normin.index)\n",
    "for column in index_score.columns:\n",
    "         index_score[column] = ((index_score[column] - 0.1) / (0.8))# rescaling to same scale as presented online       \n",
    "index_score = pd.concat([standardised_data.iloc[:, :1],index_score],axis=1)\n",
    "theme_scores = pd.DataFrame(results_stup[1], columns=['Civil Society', 'Collaboration', 'Skills', 'Infrastructure', 'Funding', 'Diversity and Inclusion'], index=df_normin.index)\n",
    "for column in theme_scores.columns:\n",
    "         theme_scores[column] = ((theme_scores[column] - 0.1) / (0.8))# rescaling to same scale as presented online     \n",
    "theme_scores = pd.concat([standardised_data.iloc[:, :1],theme_scores],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'index_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b76cc4b82d89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print final index score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'index_score' is not defined"
     ]
    }
   ],
   "source": [
    "#print final index score\n",
    "print(index_score)\n",
    "\n",
    "#write index score to .csv\n",
    "index_score.to_csv('index_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print final theme scores\n",
    "print(theme_scores)\n",
    "\n",
    "#write theme score to .csv\n",
    "theme_scores.to_csv('theme_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
